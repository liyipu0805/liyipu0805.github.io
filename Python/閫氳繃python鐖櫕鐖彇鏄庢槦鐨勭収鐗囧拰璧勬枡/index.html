<!doctype html><html lang>
<head>
<meta charset=utf-8>
<title>
通过PYTHON爬虫爬取明星的照片和资料 | 念旧's Blog
</title>
<meta name=viewport content="width=device-width,user-scalable=no,maximum-scale=1,initial-scale=1">
<link rel=canonical href=https://liyipu0805.github.io/python/%E9%96%AB%E6%B0%B3%E7%B9%83python%E9%90%96%E6%AB%95%E9%90%96%E5%BD%87%E9%8F%84%E5%BA%A2%E6%A7%A6%E9%90%A8%E5%8B%AD%E5%8F%8E%E9%90%97%E5%9B%A7%E6%8B%B0%E7%92%A7%E5%8B%AC%E6%9E%A1/>
<link rel=stylesheet href=/css/sanitize.css>
<link rel=stylesheet href=/css/responsive.css>
<link rel=stylesheet href=/css/highlight_monokai.css>
<link rel=stylesheet href=/css/theme.css>
<link rel=stylesheet href=/css/custom.css>
<link href=https://liyipu0805.github.ioindex.xml rel=alternate type=application/rss+xml title="念旧's Blog">
<link href=https://liyipu0805.github.ioindex.xml rel=feed type=application/rss+xml title="念旧's Blog">
</head>
<body>
<div class=container>
<header role=banner>
<div class="row gutters">
<div id=site-title class="col span_6">
<h1><a href=https://liyipu0805.github.io>念旧's Blog</a></h1>
</div>
<div id=social class="col span_6">
<ul>
</ul>
</div>
</div>
</header>
<main id=single role=main>
<div class=article-header>
<h1>通过PYTHON爬虫爬取明星的照片和资料</h1>
<div class=meta>
Aug 15, 2021 &nbsp;
#<a href=/tags/first>first</a>&nbsp;
</div>
</div>
<article>
<h1 id=一准备工作>一.准备工作</h1>
<h2 id=1选择合适的网站>1.选择合适的网站</h2>
<p>这次爬虫的目的，是为了为人脸识别项目提供足量的数据集。所以要求目标网站必须符合：</p>
<ol>
<li>明星信息齐全（至少包含正脸照片和姓名）</li>
<li>网站结构简洁，利于格式化爬取。</li>
</ol>
<p>通过不断的排查，最终锁定<a href=http://star.ifensi.com/>粉丝网</a>。随手打开一位明星
<img src="https://img-blog.csdnimg.cn/2021021411363332.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTkwNjQzNA==,size_16,color_FFFFFF,t_70" alt=在这里插入图片描述>发现信息齐全，并且域名非常有规律，只要改变s后面的数字，即可分分钟爬取成千上万的数据，就决定是你了！</p>
<h2 id=2安装mongodb数据库>2.安装MongoDB数据库</h2>
<p>这么大量的数据需要用数据库来合理的储存，我们选择MongoDB来进行，因为它上手简单并且可以使用Python中的pymongo库操作。</p>
<p>安装过程请教百度喔</p>
<p>安装完成后我们选择robo 3T来可视化我们的数据库，界面如下：
<img src="https://img-blog.csdnimg.cn/202102141144206.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTkwNjQzNA==,size_16,color_FFFFFF,t_70" alt=在这里插入图片描述>非常的简洁明了！</p>
<h2 id=3导入依赖库>3.导入依赖库</h2>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> requests
<span style=color:#f92672>import</span> sys
<span style=color:#f92672>import</span> re  <span style=color:#75715e>#用于正则化操作</span>
<span style=color:#f92672>from</span> lxml <span style=color:#f92672>import</span> etree
<span style=color:#75715e>#上述用于爬虫</span>
<span style=color:#f92672>import</span> pymongo <span style=color:#66d9ef>as</span> pm    <span style=color:#75715e>#链接mongoDB</span>
</code></pre></div><h1 id=二开始爬虫>二.开始爬虫</h1>
<p>首先我们链接数据库</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>client <span style=color:#f92672>=</span> pm<span style=color:#f92672>.</span>MongoClient()
db <span style=color:#f92672>=</span> client[<span style=color:#e6db74>&#39;face&#39;</span>]   <span style=color:#75715e>#访问数据库</span>
collection <span style=color:#f92672>=</span> db[<span style=color:#e6db74>&#39;my_face&#39;</span>]  <span style=color:#75715e>#访问表</span>
</code></pre></div><p>如果数据库和表不存在则会自动创建</p>
<p>接着我们构建请求头，来躲过网站的反爬虫机制。</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>headers <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;Referer&#39;</span>:<span style=color:#e6db74>&#39;https://accounts.pixiv.net/loginlang=zh&amp;source=pc&amp;view_type=page&amp;ref=wwwtop_accounts_index&#39;</span>,
           <span style=color:#e6db74>&#39;User-Agent&#39;</span>:<span style=color:#e6db74>&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36&#39;</span>
          }
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>for</span> j <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>5000</span>):
    content1 <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;http://star.ifensi.com/s</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>/&#39;</span><span style=color:#f92672>.</span>format(j),headers<span style=color:#f92672>=</span>headers)<span style=color:#f92672>.</span>text
    <span style=color:#75715e># print(content1)</span>
    root1 <span style=color:#f92672>=</span> etree<span style=color:#f92672>.</span>HTML(content1)
    <span style=color:#75715e># print(root1)</span>
    href1 <span style=color:#f92672>=</span> root1<span style=color:#f92672>.</span>xpath(<span style=color:#e6db74>&#39;//div[@class=&#34;hbox clearfix&#34;]/div[@class=&#34;hd_1&#34;]/img&#39;</span>) <span style=color:#75715e>#定位到img标签</span>
   
    name <span style=color:#f92672>=</span> root1<span style=color:#f92672>.</span>xpath(<span style=color:#e6db74>&#34;//h1[@class=&#39;t1&#39;]/text()&#34;</span>) <span style=color:#75715e>#获得明星的名字        </span>
    birth <span style=color:#f92672>=</span> root1<span style=color:#f92672>.</span>xpath(<span style=color:#e6db74>&#34;//p[@class=&#39;t2&#39;][1]//text()&#34;</span>) <span style=color:#75715e>#获得明星的身高和生日       </span>
    data <span style=color:#f92672>=</span> {}    
    <span style=color:#66d9ef>try</span>:
        data[<span style=color:#e6db74>&#34;name&#34;</span>] <span style=color:#f92672>=</span> name[<span style=color:#ae81ff>0</span>] <span style=color:#75715e>#这一步是为了排除无法访问的网站，如果网站无法访问直接进入下一循环</span>
    <span style=color:#66d9ef>except</span>:
        <span style=color:#66d9ef>continue</span>
    data[<span style=color:#e6db74>&#34;id&#34;</span>] <span style=color:#f92672>=</span> j
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(birth)):
       
        birth[i] <span style=color:#f92672>=</span> birth[i]<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\xa0</span><span style=color:#e6db74>&#34;</span>,<span style=color:#e6db74>&#34;&#34;</span>)   <span style=color:#75715e>#去空格</span>
        hanzi,number <span style=color:#f92672>=</span> re<span style=color:#f92672>.</span>findall(<span style=color:#e6db74>&#39;(.*)：(.*)&#39;</span>,birth[i])[<span style=color:#ae81ff>0</span>] <span style=color:#75715e>#分别提取出key和value</span>
        data[hanzi] <span style=color:#f92672>=</span> number  <span style=color:#75715e>#在字典中创建键值对</span>
        
    img_url <span style=color:#f92672>=</span> href1[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>attrib[<span style=color:#e6db74>&#34;src&#34;</span>]   <span style=color:#75715e>#获取图片的url</span>
    
    response <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(img_url,headers<span style=color:#f92672>=</span>headers)
    
    img <span style=color:#f92672>=</span> response<span style=color:#f92672>.</span>content
    <span style=color:#66d9ef>with</span> open( <span style=color:#e6db74>&#39;faces/</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>.jpg&#39;</span><span style=color:#f92672>.</span>format(j),<span style=color:#e6db74>&#39;wb&#39;</span> ) <span style=color:#66d9ef>as</span> f:
        f<span style=color:#f92672>.</span>write(img)           <span style=color:#75715e>#将图片保存到faces文件夹</span>
    data[<span style=color:#e6db74>&#34;path&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;faces/</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>.jpg&#39;</span><span style=color:#f92672>.</span>format(j)  <span style=color:#75715e>#保存相对路劲</span>
    
    collection<span style=color:#f92672>.</span>insert_one(data) <span style=color:#75715e>#将字典插入到表中</span>
</code></pre></div><p>正式开始爬虫操作，需要先在当前目录下创建faces文件夹，获得的明星照片会保存在这个目录。我们期望获得5000位明星的数据。</p>
<p>代码将在数据库中写入以下4个数据：</p>
<ul>
<li>ID（与保存的图片序号一致）</li>
<li>明星姓名</li>
<li>明星身高</li>
<li>明星生日</li>
<li>该明星照片的相对路径</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20210214223108953.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTkwNjQzNA==,size_16,color_FFFFFF,t_70" alt=在这里插入图片描述>
<img src="https://img-blog.csdnimg.cn/20210214223322762.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTkwNjQzNA==,size_16,color_FFFFFF,t_70" alt=在这里插入图片描述>
大功告成！</p>
</article>
</main>
<nav class=pagination-single>
<span class=previous>&larr; <a href=https://liyipu0805.github.io/python/kaoshi/ rel=prev>考试复习参考资料</a></span>
<span class=next><a href=https://liyipu0805.github.io/python/first/ rel=next>逻辑斯蒂回归LogisticRegressor处理二分类任务</a> &rarr;</span>
</nav>
<footer role=contentinfo>
<div style=text-align:center>
</div>
<a href=http://beian.miit.gov.cn/ target=_blank>皖ICP备2021019055号-1</a>
</footer>
</div>
<script src=/js/highlight.pack.js></script>
<script>hljs.initHighlightingOnLoad()</script>
<script>(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)})(window,document,'script','//www.google-analytics.com/analytics.js','ga'),ga('create','map[bing:map[siteverificationtag:XYZabc] google:map[siteverificationtag:XYZabc] yandex:map[siteverificationtag:XYZabc]]','auto'),ga('send','pageview')</script>
</body>
</html>